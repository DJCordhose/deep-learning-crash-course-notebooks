{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing our Keras model for serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# let's see what compute devices we have available, hopefully a GPU \n",
    "sess = tf.Session()\n",
    "devices = sess.list_devices()\n",
    "for d in devices:\n",
    "    print(d.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello TF!'\n"
     ]
    }
   ],
   "source": [
    "# a small sane check, does tf seem to work ok?\n",
    "hello = tf.constant('Hello TF!')\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and validating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  175k  100  175k    0     0   467k      0 --:--:-- --:--:-- --:--:--  467k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/DJCordhose/deep-learning-crash-course-notebooks/master/model/insurance.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 olive 197609 179704 Sep 14 09:35 insurance.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -l insurance.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./insurance.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descison boundaries for 2 dimensions\n",
    "\n",
    "![Descison Boundaries for 2 Dimensions](https://djcordhose.github.io/ai/img/manning/nn-reg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00259071, 0.8607017 , 0.13670751]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a little sanity check, does it work at all?\n",
    "\n",
    "# within this code, we expect Olli to be a green customer with a high prabability\n",
    "# 0: red\n",
    "# 1: green\n",
    "# 2: yellow\n",
    "\n",
    "olli_data = [100, 47, 10]\n",
    "\n",
    "X = np.array([olli_data])\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting our Keras model to the alternative high-level Estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cloud.google.com/blog/products/gcp/new-in-tensorflow-14-converting-a-keras-model-to-a-tensorflow-estimator\n",
    "estimator_model = tf.keras.estimator.model_to_estimator(keras_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'softmax': array([0.00259071, 0.8607017 , 0.13670751], dtype=float32)}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it still works the same, with a different style of API, though\n",
    "x = {\"hidden1_input\": X}\n",
    "list(estimator_model.predict(input_fn=tf.estimator.inputs.numpy_input_fn(x, shuffle=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our model for serving\n",
    "* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md\n",
    "* https://www.tensorflow.org/serving/serving_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'tf\\\\1\\\\saved_model.pb'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf tf\n",
    "\n",
    "import os\n",
    "\n",
    "export_path_base = 'tf'\n",
    "version = 1\n",
    "export_path = os.path.join(\n",
    "      tf.compat.as_bytes(export_path_base),\n",
    "      tf.compat.as_bytes(str(version)))\n",
    "\n",
    "tf.keras.backend.set_learning_phase(0)\n",
    "sess = tf.keras.backend.get_session()\n",
    "\n",
    "classification_inputs = tf.saved_model.utils.build_tensor_info(model.input)\n",
    "classification_outputs_scores = tf.saved_model.utils.build_tensor_info(model.output)\n",
    "\n",
    "signature =  tf.saved_model.signature_def_utils.build_signature_def(\n",
    "    inputs={'inputs': classification_inputs},\n",
    "    outputs={'scores': classification_outputs_scores},\n",
    "    method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "           tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature\n",
    "      })\n",
    "builder.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
